{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sb\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T02:44:39.907684Z","iopub.execute_input":"2024-08-31T02:44:39.907944Z","iopub.status.idle":"2024-08-31T02:44:42.138373Z","shell.execute_reply.started":"2024-08-31T02:44:39.907920Z","shell.execute_reply":"2024-08-31T02:44:42.137416Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv(\"/kaggle/input/playground-series-s4e8/train.csv\")\ntest_dataset = pd.read_csv(\"/kaggle/input/playground-series-s4e8/test.csv\")\n\npd.options.display.float_format = '{:.3f}'.format # Set display option for 3 decimal places","metadata":{"execution":{"iopub.status.busy":"2024-08-31T02:52:50.512426Z","iopub.execute_input":"2024-08-31T02:52:50.513627Z","iopub.status.idle":"2024-08-31T02:53:05.705244Z","shell.execute_reply.started":"2024-08-31T02:52:50.513591Z","shell.execute_reply":"2024-08-31T02:53:05.704479Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess(dataset, training=True):\n    if(not training):\n        dataset.drop_duplicates(inplace=True) #Dropping duplicates\n\n    # Impute missing numerical values\n    dataset['cap-diameter'].fillna(dataset['cap-diameter'].mean(), inplace=True)\n    dataset['stem-height'].fillna(dataset['stem-height'].mean(), inplace=True)\n    dataset['stem-width'].fillna(dataset['stem-width'].mean(), inplace=True)\n    \n    #Impute missing Categorical columns\n    categorical_cols = dataset.select_dtypes(include=\"object\").columns\n    for col in categorical_cols:\n        dataset[col].fillna('na', inplace=True)\n        #print(f\"{col} : {len(dataset[col].unique())}\") #to check cardinality\n        \n    return dataset\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-31T02:53:08.488086Z","iopub.execute_input":"2024-08-31T02:53:08.488922Z","iopub.status.idle":"2024-08-31T02:53:08.495683Z","shell.execute_reply.started":"2024-08-31T02:53:08.488886Z","shell.execute_reply":"2024-08-31T02:53:08.494614Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = preprocess(dataset=train_dataset)\ntest_dataset = preprocess(dataset=test_dataset, training=False)\n\nX_train = train_dataset.drop(['id', 'class'], axis=1)\ny_train = train_dataset['class']\n\nX_test = test_dataset.drop(['id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:38:36.702307Z","iopub.execute_input":"2024-08-31T03:38:36.702753Z","iopub.status.idle":"2024-08-31T03:38:53.032509Z","shell.execute_reply.started":"2024-08-31T03:38:36.702721Z","shell.execute_reply":"2024-08-31T03:38:53.031615Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Removing noise","metadata":{}},{"cell_type":"code","source":"com_name = 'season'\nprint(train_dataset[com_name].unique())\ncounts = train_dataset[com_name].value_counts()\n\n\ncounts = train_dataset[com_name].value_counts()\n\nprint(type(counts))  # This will print <class 'pandas.core.series.Series'>\n\n# Iterate over the counts and print each unique value with its count\nfor category, count in counts.items():\n    print(f\"Category: {category}, Count: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:32:40.572490Z","iopub.execute_input":"2024-08-31T03:32:40.572847Z","iopub.status.idle":"2024-08-31T03:32:41.545007Z","shell.execute_reply.started":"2024-08-31T03:32:40.572816Z","shell.execute_reply":"2024-08-31T03:32:41.544058Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"['a' 'w' 'u' 's']\n<class 'pandas.core.series.Series'>\nCategory: a, Count: 1543321\nCategory: u, Count: 1153588\nCategory: w, Count: 278189\nCategory: s, Count: 141847\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print unique values to inspect anomalies\nprint(train_dataset[com_name].unique())\n\n# Step 1: Identify and Handle Anomalies\n# Create a list of known valid categorical values for 'cap-shape'\nvalid_categories = ['d','l','g','h','p','m','u','w','y','na','n','a','s','k','z','b','t','c','e','r','f','o','x','i']\n\n# Step 2: Remove or Replace Anomalous Values\n# Replace anomalous values with NaN\ntrain_dataset[com_name] = train_dataset[com_name].apply(lambda x: x if x in valid_categories else 'unknown')\ntest_dataset[com_name] = train_dataset[com_name].apply(lambda x: x if x in valid_categories else 'unknown')\n\n\n# Alternatively, if you want to replace with a placeholder\n# train_dataset['cap-shape'] = train_dataset['cap-shape'].apply(lambda x: x if x in valid_categories else 'unknown')\n\n# Check again after replacing anomalies\nprint(train_dataset[com_name].unique())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:32:04.657393Z","iopub.execute_input":"2024-08-31T03:32:04.657797Z","iopub.status.idle":"2024-08-31T03:32:07.046144Z","shell.execute_reply.started":"2024-08-31T03:32:04.657763Z","shell.execute_reply":"2024-08-31T03:32:07.045092Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"['d' 'l' 'g' 'h' 'p' 'm' 'u' 'w' 'y' 'na' 'n' 'a' 's' 'k' 'habitat' 'z'\n '8.09' '17.1' 'b' 't' 'c' '9.28' 'ring-type' 'e' 'r'\n 'does-bruise-or-bleed' 'f' 'is w' 'o' '2.94' 'x' '4' 'is h' '5.56'\n 'class' 'i' '10.07' '7.31' '5.62' 'spore-print-color' 'cap-diameter'\n '3.11' '16.46' '7.37' 'veil-type' '17.38' '1.66' '6.63' '18.35' '6.75'\n '2.44' '3.68' '2.25']\n['d' 'l' 'g' 'h' 'p' 'm' 'u' 'w' 'y' 'na' 'n' 'a' 's' 'k' 'unknown' 'z'\n 'b' 't' 'c' 'e' 'r' 'f' 'o' 'x' 'i']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define file paths\ntrain_file_path = 'train_dataset_preprocessed.csv'\ntest_file_path = 'test_dataset_preprocessed.csv'\n\n# Save the preprocessed train dataset to a CSV file\ntrain_dataset.to_csv(train_file_path, index=False)\n\n# Save the preprocessed test dataset to a CSV file\ntest_dataset.to_csv(test_file_path, index=False)\n\nprint(f\"Train dataset saved to {train_file_path}\")\nprint(f\"Test dataset saved to {test_file_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:36:02.407256Z","iopub.execute_input":"2024-08-31T03:36:02.407629Z","iopub.status.idle":"2024-08-31T03:36:50.083255Z","shell.execute_reply.started":"2024-08-31T03:36:02.407600Z","shell.execute_reply":"2024-08-31T03:36:50.081389Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Train dataset saved to train_dataset_preprocessed.csv\nTest dataset saved to test_dataset_preprocessed.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:32:07.047965Z","iopub.execute_input":"2024-08-31T03:32:07.048379Z","iopub.status.idle":"2024-08-31T03:32:07.052938Z","shell.execute_reply.started":"2024-08-31T03:32:07.048325Z","shell.execute_reply":"2024-08-31T03:32:07.051839Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport category_encoders as ce\n\nlabel_encoder = LabelEncoder()\n\ndef encode_y(y_train, y_test=None):\n    \n    y_train = label_encoder.fit_transform(y_train)\n    if(y_test is not None): \n        y_test = label_encoder.transform(y_test)\n        \n    return (y_train, y_test)\n    \n    \ndef encode_X(X_train, y_train, X_test=None, categorical_cols=None):\n    \n    #target_encoder = ce.TargetEncoder(cols= categorical_cols.drop('class'))\n    target_encoder = ce.TargetEncoder(cols= categorical_cols)\n    X_train = target_encoder.fit_transform(X_train, y_train)\n    if(X_test is not None):\n        X_test = target_encoder.transform(X_test)\n    \n    return (X_train, X_test)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:39:04.422616Z","iopub.execute_input":"2024-08-31T03:39:04.423001Z","iopub.status.idle":"2024-08-31T03:39:04.430813Z","shell.execute_reply.started":"2024-08-31T03:39:04.422969Z","shell.execute_reply":"2024-08-31T03:39:04.429731Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"y_train, _ = encode_y(y_train=y_train)\n\nX_train, X_test = encode_X(X_train=X_train, y_train=y_train, X_test=X_test, categorical_cols=X_train.select_dtypes(include=\"object\").columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:39:07.530921Z","iopub.execute_input":"2024-08-31T03:39:07.531333Z","iopub.status.idle":"2024-08-31T03:40:20.836240Z","shell.execute_reply.started":"2024-08-31T03:39:07.531301Z","shell.execute_reply":"2024-08-31T03:40:20.835466Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# correlation_matrix = X_train.corr().round(2)\n\n# plt.figure(figsize=(12, 8))\n# sb.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n# plt.show()\n# stem-width and cap-diameter are highly correlated ","metadata":{"execution":{"iopub.status.busy":"2024-08-28T12:03:48.705446Z","iopub.execute_input":"2024-08-28T12:03:48.705770Z","iopub.status.idle":"2024-08-28T12:03:48.709923Z","shell.execute_reply.started":"2024-08-28T12:03:48.705734Z","shell.execute_reply":"2024-08-28T12:03:48.709100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature scaling is not necessary for a random forest classifier. But it slighly increase the accuracy\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\ndef feature_scale(num_cols, X_train, X_test=None):\n\n    #numerical_cols = ['cap-diameter','stem-height', 'stem-width']\n    ct = ColumnTransformer(transformers=[('feature_scaler', StandardScaler(), num_cols)] , remainder='passthrough' )\n\n    X_train = ct.fit_transform(X_train)\n    if(X_test is not None):\n        X_test = ct.transform(X_test)\n        \n    return (X_train, X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:40:24.473236Z","iopub.execute_input":"2024-08-31T03:40:24.473643Z","iopub.status.idle":"2024-08-31T03:40:24.479757Z","shell.execute_reply.started":"2024-08-31T03:40:24.473609Z","shell.execute_reply":"2024-08-31T03:40:24.478784Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"num_cols = ['cap-diameter','stem-height', 'stem-width']\nX_train, X_test = feature_scale(num_cols=num_cols, X_train=X_train, X_test=X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T03:40:30.243803Z","iopub.execute_input":"2024-08-31T03:40:30.244242Z","iopub.status.idle":"2024-08-31T03:40:31.175985Z","shell.execute_reply.started":"2024-08-31T03:40:30.244193Z","shell.execute_reply":"2024-08-31T03:40:31.174894Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## XGB Model","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold, cross_val_score\n# from sklearn.metrics import matthews_corrcoef, make_scorer\n# from xgboost import XGBClassifier\n\n\n# Xparams_s1 = {'n_estimators': 948,\n#            'max_depth': 12,\n#            'learning_rate': 0.025559161851111477, \n#            'reg_alpha': 0.7178566258816612, \n#            'reg_lambda': 0.00029868510908985876,\n#            'subsample': 0.7997054056983265, \n#            'colsample_bytree': 0.5013225770330585}\n\n# Xparams_s2 = {'n_estimators': 1396, \n#               'max_depth': 19, \n#               'learning_rate': 0.010455050159676566, \n#               'subsample': 0.8006842727555243, \n#               'colsample_bytree': 0.5001438770455072, \n#               'colsample_bylevel': 0.8027576507794217, \n#               'min_child_weight': 5,\n#               'reg_alpha': 1.1586967014672253e-08, \n#               'reg_lambda': 3.3517458803447213e-06, \n#               'gamma': 0.01841032988451454}\n\n# Define the model\n# xgb_clf = XGBClassifier(**Xparams_s2, tree_method='gpu_hist', random_state=42)\n\n# # Define the k-fold cross-validator\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # Create a custom scorer for MCC\n# mcc_scorer = make_scorer(matthews_corrcoef)\n\n# # Perform cross-validation with MCC as the scoring metric\n# scores = cross_val_score(xgb_clf, X_train, y_train, cv=kfold, scoring=mcc_scorer)\n\n# # Print the MCC for each fold\n# print(\"MCC for each fold: \", scores)\n\n# # Print the mean MCC and standard deviation\n# print(\"Mean MCC: {:.2f}\".format(scores.mean()))\n# print(\"Standard deviation of MCC: {:.2f}\".format(scores.std()))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T12:03:49.726761Z","iopub.execute_input":"2024-08-28T12:03:49.727159Z","iopub.status.idle":"2024-08-28T12:03:49.735581Z","shell.execute_reply.started":"2024-08-28T12:03:49.727121Z","shell.execute_reply":"2024-08-28T12:03:49.734449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T12:03:49.736687Z","iopub.execute_input":"2024-08-28T12:03:49.737011Z","iopub.status.idle":"2024-08-28T12:03:49.748001Z","shell.execute_reply.started":"2024-08-28T12:03:49.736985Z","shell.execute_reply":"2024-08-28T12:03:49.746818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import xgboost as xgb\n\n# xgb_clf.save_model('xgb_classifier_model.bin')\n\n# # Load the model back from the file\n# loaded_model = XGBClassifier()\n# loaded_model.load_model('xgb_classifier_model.bin')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T12:03:49.749338Z","iopub.execute_input":"2024-08-28T12:03:49.749683Z","iopub.status.idle":"2024-08-28T12:03:49.757553Z","shell.execute_reply.started":"2024-08-28T12:03:49.749657Z","shell.execute_reply":"2024-08-28T12:03:49.756615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tune XGB model ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import make_scorer, matthews_corrcoef\nfrom xgboost import XGBClassifier, DMatrix\nfrom skopt import BayesSearchCV\nimport numpy as np\n\nXparams_s2 = {'n_estimators': 1396, \n              'max_depth': 19, \n              'learning_rate': 0.010455050159676566, \n              'subsample': 0.8006842727555243, \n              'colsample_bytree': 0.5001438770455072, \n              'colsample_bylevel': 0.8027576507794217, \n              'min_child_weight': 5,\n              'reg_alpha': 1.1586967014672253e-08, \n              'reg_lambda': 3.3517458803447213e-06, \n              'gamma': 0.01841032988451454}\nXparams_s3 = {'subsample': 0.7888888888888889, \n              'reg_lambda': 0.00046415888336127817, \n              'reg_alpha': 1.6681005372000592e-08, \n              'n_estimators': 1340, \n              'min_child_weight': 1, \n              'max_depth': 20, \n              'learning_rate': 0.009444444444444443, \n              'gamma': 0.0, \n              'enable_categorical': False, \n              'colsample_bytree': 0.4222222222222222, \n              'colsample_bylevel': 0.8111111111111111}\n\nparam_grid = {\n    'n_estimators': np.arange(1200, 1500, 1),  # Tuning around the current value\n    'max_depth': np.arange(15, 22, 1),  # Fine-tuning max_depth\n    'learning_rate': np.linspace(0.001, 0.02, 20),  # Narrow down around current learning rate\n    'subsample': np.linspace(0.7, 0.9, 10),  # Adjust subsample range\n    'colsample_bytree': np.linspace(0.4, 0.6, 10),  # Tuning colsample_bytree\n    'colsample_bylevel': np.linspace(0.7, 0.9, 10),  # Tuning colsample_bylevel\n    'min_child_weight': np.arange(1, 7, 1),  # Tuning min_child_weight\n    'reg_alpha': np.logspace(-10, 0, 10),  # Regularization alpha tuning\n    'reg_lambda': np.logspace(-10, 0, 10),  # Regularization lambda tuning\n    'gamma': np.linspace(0, 0.1, 10),  # Tuning gamma\n    'enable_categorical': [True, False]\n}\n\ndtrain = DMatrix(X_train, label=y_train)\n\nxgb_clf = XGBClassifier(\n    tree_method='hist',\n    device='cuda',\n#     enable_categorical=True,\n    random_state=42,\n    **Xparams_s3,\n#     predictor='gpu_predictor'\n)\n# xgb_clf.set_params(predictor='gpu_predictor')\n\nmcc_scorer = make_scorer(matthews_corrcoef)\n\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nbayes_search = BayesSearchCV(\n    estimator=xgb_clf,\n    search_spaces=param_grid,\n    n_iter=10,  # Number of parameter settings that are sampled\n    cv=None,\n    scoring=mcc_scorer,\n    verbose=3,\n    n_jobs=-1\n)\n\n# Fit BayesSearch\nbayes_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T04:04:50.064943Z","iopub.execute_input":"2024-08-31T04:04:50.065532Z","iopub.status.idle":"2024-08-31T05:49:52.486074Z","shell.execute_reply.started":"2024-08-31T04:04:50.065483Z","shell.execute_reply":"2024-08-31T05:49:52.484970Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:10:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:10:23] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:10:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:10:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\nFitting 5 folds for each of 1 candidates, totalling 5 fits\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 4/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.044444444444444446, learning_rate=0.009000000000000001, max_depth=16, min_child_weight=5, n_estimators=1424, reg_alpha=0.005994842503189421, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.5min\n[CV 5/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.044444444444444446, learning_rate=0.009000000000000001, max_depth=16, min_child_weight=5, n_estimators=1424, reg_alpha=0.005994842503189421, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 1.5min\n[CV 4/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5111111111111111, enable_categorical=True, gamma=0.022222222222222223, learning_rate=0.012, max_depth=17, min_child_weight=6, n_estimators=1213, reg_alpha=2.1544346900318867e-07, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.0min\n[CV 2/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.017, max_depth=17, min_child_weight=4, n_estimators=1295, reg_alpha=1.0, reg_lambda=9.999999999999999e-11, subsample=0.7222222222222222;, score=0.985 total time= 4.0min\n[CV 2/5] END colsample_bylevel=0.7, colsample_bytree=0.4666666666666667, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.005, max_depth=20, min_child_weight=5, n_estimators=1341, reg_alpha=9.999999999999999e-11, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 8.7min\n[CV 1/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.044444444444444446, learning_rate=0.009000000000000001, max_depth=16, min_child_weight=5, n_estimators=1424, reg_alpha=0.005994842503189421, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.5min\n[CV 1/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5111111111111111, enable_categorical=True, gamma=0.022222222222222223, learning_rate=0.012, max_depth=17, min_child_weight=6, n_estimators=1213, reg_alpha=2.1544346900318867e-07, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.0min\n[CV 5/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5111111111111111, enable_categorical=True, gamma=0.022222222222222223, learning_rate=0.012, max_depth=17, min_child_weight=6, n_estimators=1213, reg_alpha=2.1544346900318867e-07, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 1.4min\n[CV 4/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.017, max_depth=17, min_child_weight=4, n_estimators=1295, reg_alpha=1.0, reg_lambda=9.999999999999999e-11, subsample=0.7222222222222222;, score=0.984 total time= 4.0min\n[CV 5/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.017, max_depth=17, min_child_weight=4, n_estimators=1295, reg_alpha=1.0, reg_lambda=9.999999999999999e-11, subsample=0.7222222222222222;, score=0.985 total time= 1.2min\n[CV 4/5] END colsample_bylevel=0.7, colsample_bytree=0.4666666666666667, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.005, max_depth=20, min_child_weight=5, n_estimators=1341, reg_alpha=9.999999999999999e-11, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 8.7min\n[CV 2/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.044444444444444446, learning_rate=0.009000000000000001, max_depth=16, min_child_weight=5, n_estimators=1424, reg_alpha=0.005994842503189421, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.6min\n[CV 3/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5111111111111111, enable_categorical=True, gamma=0.022222222222222223, learning_rate=0.012, max_depth=17, min_child_weight=6, n_estimators=1213, reg_alpha=2.1544346900318867e-07, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.0min\n[CV 1/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.017, max_depth=17, min_child_weight=4, n_estimators=1295, reg_alpha=1.0, reg_lambda=9.999999999999999e-11, subsample=0.7222222222222222;, score=0.985 total time= 4.0min\n[CV 1/5] END colsample_bylevel=0.7, colsample_bytree=0.4666666666666667, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.005, max_depth=20, min_child_weight=5, n_estimators=1341, reg_alpha=9.999999999999999e-11, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 8.7min\n[CV 3/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.044444444444444446, learning_rate=0.009000000000000001, max_depth=16, min_child_weight=5, n_estimators=1424, reg_alpha=0.005994842503189421, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.5min\n[CV 2/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5111111111111111, enable_categorical=True, gamma=0.022222222222222223, learning_rate=0.012, max_depth=17, min_child_weight=6, n_estimators=1213, reg_alpha=2.1544346900318867e-07, reg_lambda=2.1544346900318867e-07, subsample=0.7888888888888889;, score=0.985 total time= 5.0min\n[CV 3/5] END colsample_bylevel=0.8555555555555556, colsample_bytree=0.4444444444444445, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.017, max_depth=17, min_child_weight=4, n_estimators=1295, reg_alpha=1.0, reg_lambda=9.999999999999999e-11, subsample=0.7222222222222222;, score=0.985 total time= 4.0min\n[CV 3/5] END colsample_bylevel=0.7, colsample_bytree=0.4666666666666667, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.005, max_depth=20, min_child_weight=5, n_estimators=1341, reg_alpha=9.999999999999999e-11, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 8.7min\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:34:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:40:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:40:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:40:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 2/5] END colsample_bylevel=0.9, colsample_bytree=0.5333333333333333, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.007, max_depth=16, min_child_weight=6, n_estimators=1332, reg_alpha=0.005994842503189421, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 5.9min\n[CV 3/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.003, max_depth=17, min_child_weight=6, n_estimators=1498, reg_alpha=3.5938136638046256e-05, reg_lambda=1.6681005372000592e-08, subsample=0.8333333333333334;, score=0.985 total time= 8.1min\n[CV 3/5] END colsample_bylevel=0.9, colsample_bytree=0.5333333333333333, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.007, max_depth=16, min_child_weight=6, n_estimators=1332, reg_alpha=0.005994842503189421, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 5.9min\n[CV 2/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.003, max_depth=17, min_child_weight=6, n_estimators=1498, reg_alpha=3.5938136638046256e-05, reg_lambda=1.6681005372000592e-08, subsample=0.8333333333333334;, score=0.984 total time= 8.1min\n[CV 4/5] END colsample_bylevel=0.9, colsample_bytree=0.5333333333333333, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.007, max_depth=16, min_child_weight=6, n_estimators=1332, reg_alpha=0.005994842503189421, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.984 total time= 5.9min\n[CV 1/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.003, max_depth=17, min_child_weight=6, n_estimators=1498, reg_alpha=3.5938136638046256e-05, reg_lambda=1.6681005372000592e-08, subsample=0.8333333333333334;, score=0.985 total time= 8.1min\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 5/5] END colsample_bylevel=0.7, colsample_bytree=0.4666666666666667, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.005, max_depth=20, min_child_weight=5, n_estimators=1341, reg_alpha=9.999999999999999e-11, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 2.2min\n[CV 1/5] END colsample_bylevel=0.9, colsample_bytree=0.5333333333333333, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.007, max_depth=16, min_child_weight=6, n_estimators=1332, reg_alpha=0.005994842503189421, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 5.8min\n[CV 5/5] END colsample_bylevel=0.9, colsample_bytree=0.5333333333333333, enable_categorical=True, gamma=0.06666666666666667, learning_rate=0.007, max_depth=16, min_child_weight=6, n_estimators=1332, reg_alpha=0.005994842503189421, reg_lambda=9.999999999999999e-11, subsample=0.8333333333333334;, score=0.985 total time= 1.6min\n[CV 4/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.003, max_depth=17, min_child_weight=6, n_estimators=1498, reg_alpha=3.5938136638046256e-05, reg_lambda=1.6681005372000592e-08, subsample=0.8333333333333334;, score=0.984 total time= 8.0min\n[CV 5/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.003, max_depth=17, min_child_weight=6, n_estimators=1498, reg_alpha=3.5938136638046256e-05, reg_lambda=1.6681005372000592e-08, subsample=0.8333333333333334;, score=0.985 total time= 2.2min\n[CV 1/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.4666666666666667, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.009000000000000001, max_depth=21, min_child_weight=2, n_estimators=1361, reg_alpha=9.999999999999999e-11, reg_lambda=2.782559402207126e-06, subsample=0.7222222222222222;, score=0.985 total time= 9.9min\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:02:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:02:04] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:02:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:04:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 3/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.4666666666666667, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.009000000000000001, max_depth=21, min_child_weight=2, n_estimators=1361, reg_alpha=9.999999999999999e-11, reg_lambda=2.782559402207126e-06, subsample=0.7222222222222222;, score=0.985 total time=10.0min\n[CV 2/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.005, max_depth=17, min_child_weight=2, n_estimators=1288, reg_alpha=0.00046415888336127817, reg_lambda=9.999999999999999e-11, subsample=0.7444444444444445;, score=0.985 total time= 7.9min\n[CV 2/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5333333333333333, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.012, max_depth=18, min_child_weight=1, n_estimators=1354, reg_alpha=0.005994842503189421, reg_lambda=3.5938136638046256e-05, subsample=0.7888888888888889;, score=0.985 total time= 9.0min\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 4/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.4666666666666667, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.009000000000000001, max_depth=21, min_child_weight=2, n_estimators=1361, reg_alpha=9.999999999999999e-11, reg_lambda=2.782559402207126e-06, subsample=0.7222222222222222;, score=0.984 total time=10.0min\n[CV 3/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.005, max_depth=17, min_child_weight=2, n_estimators=1288, reg_alpha=0.00046415888336127817, reg_lambda=9.999999999999999e-11, subsample=0.7444444444444445;, score=0.985 total time= 7.8min\n[CV 5/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.005, max_depth=17, min_child_weight=2, n_estimators=1288, reg_alpha=0.00046415888336127817, reg_lambda=9.999999999999999e-11, subsample=0.7444444444444445;, score=0.985 total time= 2.1min\n[CV 4/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5333333333333333, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.012, max_depth=18, min_child_weight=1, n_estimators=1354, reg_alpha=0.005994842503189421, reg_lambda=3.5938136638046256e-05, subsample=0.7888888888888889;, score=0.984 total time= 8.9min\n[CV 5/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5333333333333333, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.012, max_depth=18, min_child_weight=1, n_estimators=1354, reg_alpha=0.005994842503189421, reg_lambda=3.5938136638046256e-05, subsample=0.7888888888888889;, score=0.985 total time= 2.3min\n[CV 3/5] END colsample_bylevel=0.8111111111111111, colsample_bytree=0.4444444444444445, enable_categorical=True, gamma=0.011111111111111112, learning_rate=0.006, max_depth=20, min_child_weight=1, n_estimators=1422, reg_alpha=3.5938136638046256e-05, reg_lambda=2.1544346900318867e-07, subsample=0.7444444444444445;, score=0.985 total time=15.7min\n[CV 2/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.4666666666666667, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.009000000000000001, max_depth=21, min_child_weight=2, n_estimators=1361, reg_alpha=9.999999999999999e-11, reg_lambda=2.782559402207126e-06, subsample=0.7222222222222222;, score=0.985 total time= 9.9min\n[CV 1/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.005, max_depth=17, min_child_weight=2, n_estimators=1288, reg_alpha=0.00046415888336127817, reg_lambda=9.999999999999999e-11, subsample=0.7444444444444445;, score=0.985 total time= 7.9min\n[CV 3/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5333333333333333, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.012, max_depth=18, min_child_weight=1, n_estimators=1354, reg_alpha=0.005994842503189421, reg_lambda=3.5938136638046256e-05, subsample=0.7888888888888889;, score=0.985 total time= 9.0min\n[CV 1/5] END colsample_bylevel=0.8111111111111111, colsample_bytree=0.4444444444444445, enable_categorical=True, gamma=0.011111111111111112, learning_rate=0.006, max_depth=20, min_child_weight=1, n_estimators=1422, reg_alpha=3.5938136638046256e-05, reg_lambda=2.1544346900318867e-07, subsample=0.7444444444444445;, score=0.985 total time=15.9min\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:41:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[CV 5/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.4666666666666667, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.009000000000000001, max_depth=21, min_child_weight=2, n_estimators=1361, reg_alpha=9.999999999999999e-11, reg_lambda=2.782559402207126e-06, subsample=0.7222222222222222;, score=0.985 total time= 2.5min\n[CV 4/5] END colsample_bylevel=0.7, colsample_bytree=0.4888888888888889, enable_categorical=False, gamma=0.06666666666666667, learning_rate=0.005, max_depth=17, min_child_weight=2, n_estimators=1288, reg_alpha=0.00046415888336127817, reg_lambda=9.999999999999999e-11, subsample=0.7444444444444445;, score=0.984 total time= 7.8min\n[CV 1/5] END colsample_bylevel=0.7222222222222222, colsample_bytree=0.5333333333333333, enable_categorical=False, gamma=0.05555555555555556, learning_rate=0.012, max_depth=18, min_child_weight=1, n_estimators=1354, reg_alpha=0.005994842503189421, reg_lambda=3.5938136638046256e-05, subsample=0.7888888888888889;, score=0.985 total time= 9.0min\n[CV 2/5] END colsample_bylevel=0.8111111111111111, colsample_bytree=0.4444444444444445, enable_categorical=True, gamma=0.011111111111111112, learning_rate=0.006, max_depth=20, min_child_weight=1, n_estimators=1422, reg_alpha=3.5938136638046256e-05, reg_lambda=2.1544346900318867e-07, subsample=0.7444444444444445;, score=0.985 total time=15.9min\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[CV 4/5] END colsample_bylevel=0.8111111111111111, colsample_bytree=0.4444444444444445, enable_categorical=True, gamma=0.011111111111111112, learning_rate=0.006, max_depth=20, min_child_weight=1, n_estimators=1422, reg_alpha=3.5938136638046256e-05, reg_lambda=2.1544346900318867e-07, subsample=0.7444444444444445;, score=0.985 total time=15.9min\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"BayesSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n                                      callbacks=None,\n                                      colsample_bylevel=0.8111111111111111,\n                                      colsample_bynode=None,\n                                      colsample_bytree=0.4222222222222222,\n                                      device='cuda', early_stopping_rounds=None,\n                                      enable_categorical=False,\n                                      eval_metric=None, feature_types=None,\n                                      gamma=0.0, grow_policy=None,\n                                      importance_type=None,\n                                      interaction_constraints...\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             'reg_lambda': array([1.00000000e-10, 1.29154967e-09, 1.66810054e-08, 2.15443469e-07,\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             'subsample': array([0.7       , 0.72222222, 0.74444444, 0.76666667, 0.78888889,\n       0.81111111, 0.83333333, 0.85555556, 0.87777778, 0.9       ])},\n              verbose=3)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n                                      callbacks=None,\n                                      colsample_bylevel=0.8111111111111111,\n                                      colsample_bynode=None,\n                                      colsample_bytree=0.4222222222222222,\n                                      device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n                                      enable_categorical=False,\n                                      eval_metric=None, feature_types=None,\n                                      gamma=0.0, grow_policy=None,\n                                      importance_type=None,\n                                      interaction_constraints...\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             &#x27;reg_lambda&#x27;: array([1.00000000e-10, 1.29154967e-09, 1.66810054e-08, 2.15443469e-07,\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             &#x27;subsample&#x27;: array([0.7       , 0.72222222, 0.74444444, 0.76666667, 0.78888889,\n       0.81111111, 0.83333333, 0.85555556, 0.87777778, 0.9       ])},\n              verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n                                      callbacks=None,\n                                      colsample_bylevel=0.8111111111111111,\n                                      colsample_bynode=None,\n                                      colsample_bytree=0.4222222222222222,\n                                      device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n                                      enable_categorical=False,\n                                      eval_metric=None, feature_types=None,\n                                      gamma=0.0, grow_policy=None,\n                                      importance_type=None,\n                                      interaction_constraints...\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             &#x27;reg_lambda&#x27;: array([1.00000000e-10, 1.29154967e-09, 1.66810054e-08, 2.15443469e-07,\n       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n       7.74263683e-02, 1.00000000e+00]),\n                             &#x27;subsample&#x27;: array([0.7       , 0.72222222, 0.74444444, 0.76666667, 0.78888889,\n       0.81111111, 0.83333333, 0.85555556, 0.87777778, 0.9       ])},\n              verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=0.8111111111111111, colsample_bynode=None,\n              colsample_bytree=0.4222222222222222, device=&#x27;cuda&#x27;,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, feature_types=None, gamma=0.0, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.009444444444444443, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=20, max_leaves=None,\n              min_child_weight=1, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1340, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=0.8111111111111111, colsample_bynode=None,\n              colsample_bytree=0.4222222222222222, device=&#x27;cuda&#x27;,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, feature_types=None, gamma=0.0, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.009444444444444443, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=20, max_leaves=None,\n              min_child_weight=1, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1340, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Get the best parameters and the best MCC score\nprint(\"Best Parameters: \", bayes_search.best_params_)\nprint(\"Best MCC Score: {:.5f}\".format(bayes_search.best_score_))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:50:12.534417Z","iopub.execute_input":"2024-08-31T05:50:12.534999Z","iopub.status.idle":"2024-08-31T05:50:12.539875Z","shell.execute_reply.started":"2024-08-31T05:50:12.534968Z","shell.execute_reply":"2024-08-31T05:50:12.538934Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Best Parameters:  OrderedDict([('colsample_bylevel', 0.8111111111111111), ('colsample_bytree', 0.4444444444444445), ('enable_categorical', True), ('gamma', 0.011111111111111112), ('learning_rate', 0.006), ('max_depth', 20), ('min_child_weight', 1), ('n_estimators', 1422), ('reg_alpha', 3.5938136638046256e-05), ('reg_lambda', 2.1544346900318867e-07), ('subsample', 0.7444444444444445)])\nBest MCC Score: 0.98486\n[CV 5/5] END colsample_bylevel=0.8111111111111111, colsample_bytree=0.4444444444444445, enable_categorical=True, gamma=0.011111111111111112, learning_rate=0.006, max_depth=20, min_child_weight=1, n_estimators=1422, reg_alpha=3.5938136638046256e-05, reg_lambda=2.1544346900318867e-07, subsample=0.7444444444444445;, score=0.985 total time= 4.0min\n","output_type":"stream"}]},{"cell_type":"code","source":"from joblib import dump, load\n\n# # Save the RandomizedSearchCV object to a file\ndump(bayes_search, 'bayes_search.joblib')\n\n# # Later on, load the RandomizedSearchCV object from the file\n# loaded_random_search = load('random_search_xgb.joblib')\n\n# # Access the best model or other attributes\n# print(\"Best parameters found: \", loaded_random_search.best_params_)\n# print(\"Best score achieved: \", loaded_random_search.best_score_)\n\n# {'subsample': 0.8111111111111111, 'reg_lambda': 1.0, 'reg_alpha': 1.6681005372000592e-08, 'n_estimators': 1200, 'min_child_weight': 5, 'max_depth': 21, 'learning_rate': 0.009444444444444443, 'gamma': 0.03333333333333333, 'colsample_bytree': 0.4888888888888889, 'colsample_bylevel': 0.7444444444444445}","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:50:51.699197Z","iopub.execute_input":"2024-08-31T05:50:51.699891Z","iopub.status.idle":"2024-08-31T05:50:55.214783Z","shell.execute_reply.started":"2024-08-31T05:50:51.699855Z","shell.execute_reply":"2024-08-31T05:50:55.213826Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"['bayes_search.joblib']"},"metadata":{}}]},{"cell_type":"markdown","source":"## Submission set","metadata":{}},{"cell_type":"code","source":"# y_pred = xgb_clf.predict(X_test)\ny_pred = bayes_search.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:51:02.440621Z","iopub.execute_input":"2024-08-31T05:51:02.441287Z","iopub.status.idle":"2024-08-31T05:51:05.675167Z","shell.execute_reply.started":"2024-08-31T05:51:02.441256Z","shell.execute_reply":"2024-08-31T05:51:05.674146Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"predictions = label_encoder.inverse_transform(y_pred)\ny_pred = pd.DataFrame({'id': test_dataset['id'], 'class': predictions})\ny_pred.to_csv('submission_xgboost_bayseyanSearch_removeNoise.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T05:51:23.769439Z","iopub.execute_input":"2024-08-31T05:51:23.770031Z","iopub.status.idle":"2024-08-31T05:51:26.244859Z","shell.execute_reply.started":"2024-08-31T05:51:23.769997Z","shell.execute_reply":"2024-08-31T05:51:26.244060Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}